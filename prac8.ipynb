{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a218a5a6",
   "metadata": {},
   "source": [
    "## Learning outcomes\n",
    "- IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a919c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f4d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750997c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758beb9",
   "metadata": {},
   "source": [
    "## IOU\n",
    "Intersection over Union (IoU) is a commonly used performance metric in object detection tasks in machine learning. It measures the overlap between the predicted bounding box of an object and the ground truth bounding box in an image.\n",
    "FORMULA:\n",
    "\n",
    "$$IOU = \\frac{| A \\cap B |}{| A \\cup B |}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbe80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIOU(boxA, boxB):\n",
    "    \"\"\"boxA and boxB are of xyxy formats\"\"\"\n",
    "    x_start = max(boxA[0], boxB[0])\n",
    "    y_start = max(boxA[1], boxB[1])\n",
    "    x_end = min(boxA[2], boxB[2])\n",
    "    y_end = min(boxA[3], boxB[3])\n",
    "    \n",
    "    interArea = max(0, x_end - x_start + 1) * max(0, y_end - y_start + 1)\n",
    "    \n",
    "    areaA = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    areaB = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    return interArea / (areaA + areaB - interArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ad1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fce94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = cv.selectROIs(\"bounding box\", img, showCrosshair = False)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# drag a bounding box then hit spacebar\n",
    "# drag another bounding box then hit spacebar again\n",
    "# Press Esc twice to quit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee829f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xywh_to_xyxy(box):\n",
    "    return [box[0], box[1], box[0] + box[2], box[1] + box[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = convert_xywh_to_xyxy(boxes[0])\n",
    "pred = convert_xywh_to_xyxy(boxes[1])\n",
    "\n",
    "img_copy = img.copy()\n",
    "cv.rectangle(img_copy, (gt[0], gt[1]), (gt[2],gt[3]), (0, 0, 255), 2)\n",
    "cv.rectangle(img_copy, (pred[0], pred[1]), (pred[2],pred[3]), (255, 0, 0), 2)\n",
    "cv.putText(img_copy, f\"IOU: {computeIOU(gt, pred):.3f}\",(10, 25),\n",
    "          cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "show_img(\"IOU\", img_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca0d8c",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "Edge detection is a process that aims to identify the boundaries of objects within an image. Edge detection methods emphasize areas of the image where there is a rapid change in intensity, which typically corresponds to object boundaries.\n",
    "2 techniques: 1) Sobel operation 2) Canny operation\n",
    "Sobel x operator kernel formulation:\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 0 & 1\\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0de279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#techinque 1 : sobel operation\n",
    "img = cv.imread(\"images/wood_planck.jfif\", 0)\n",
    "\n",
    "th = cv.threshold(img, 200, 255, cv.THRESH_BINARY_INV)[1]\n",
    "\n",
    "show_img(\"binary\", th)\n",
    "#sobel operators (wrong way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong way\n",
    "sobelx_8u = cv.Sobel(th, cv.CV_8U, 0, 1)\n",
    "\n",
    "# correct way\n",
    "sobelx_32f = cv.Sobel(th, cv.CV_32F, 0, 1)\n",
    "sobelx = cv.convertScaleAbs(sobelx_32f)   # absolute and convert to uint8\n",
    "\n",
    "plt.subplot(121), plt_img(sobelx_8u, \"wrong\")\n",
    "plt.subplot(122), plt_img(sobelx, \"correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03965d99",
   "metadata": {},
   "source": [
    "### combine x and y edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/chessboard.png\", 0)\n",
    "\n",
    "# sobel x and y\n",
    "sobelx_32f = cv.Sobel(img, cv.CV_32F, 1, 0)\n",
    "sobelx = cv.convertScaleAbs(sobelx_32f)\n",
    "sobely_32f = cv.Sobel(img, cv.CV_32F, 0, 1)\n",
    "sobely = cv.convertScaleAbs(sobely_32f)\n",
    "\n",
    "# gradient and direction\n",
    "gradient = cv.magnitude(sobelx_32f, sobely_32f)\n",
    "direction = cv.phase(sobelx_32f, sobely_32f, angleInDegrees=True) % 180\n",
    "\n",
    "plt.subplot(221), plt_img(sobelx, \"vertical\")\n",
    "plt.subplot(222), plt_img(sobely, \"horizontal\")\n",
    "plt.subplot(223), plt.imshow(gradient, cmap=\"jet\"), plt.title(\"gradient\")\n",
    "plt.colorbar()\n",
    "plt.subplot(224), plt.imshow(direction, cmap=\"jet\"), plt.title(\"direction\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70608ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#technique 2: Canny operation \n",
    "img = cv.imread(\"images/chair.jpg\", 0)\n",
    "\n",
    "edge = cv.Canny(img, 100, 300)\n",
    "\n",
    "plt.subplot(121), plt_img(img, \"grayscale\")\n",
    "plt.subplot(122), plt_img(edge, \"Canny\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/chair.jpg\", 0)\n",
    "\n",
    "edge = cv.Canny(img, 30, 150)\n",
    "\n",
    "plt.subplot(121), plt_img(img, \"grayscale\")\n",
    "plt.subplot(122), plt_img(edge, \"Canny\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938b68b",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Create a trackbar that control the hysterisis thresholds and display the resulting images from the changes in the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a515e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/pineapple.jfif\")\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "ratio = 2.5\n",
    "trackbar_name = \"Th1\"\n",
    "wn = \"Canny\"\n",
    "ksize = 3\n",
    "\n",
    "def cannyThreshold(val):\n",
    "    \"\"\"Trackbar callback function\"\"\"\n",
    "    edge = cv.Canny(gray, val, ratio*val, apertureSize=ksize)\n",
    "    mask = edge != 0\n",
    "    res = img * (mask[:, :, None].astype(np.uint8))\n",
    "    cv.imshow(wn, res)\n",
    "    \n",
    "cv.namedWindow(wn)\n",
    "cv.createTrackbar(trackbar_name, wn, 10, 100, cannyThreshold)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a887aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(img, method, sigma=0.33):\n",
    "    \"\"\"Args:\n",
    "    img: grayscale image\n",
    "    method: median, otsu, triangle\n",
    "    sigma:0.33 (default)\"\"\"\n",
    "    if method == \"median\":\n",
    "        Th = np.median(img)\n",
    "    \n",
    "    elif method == \"otsu\":\n",
    "        Th = cv.threshold(img, 0, 255, cv.THRESH_OTSU)[0]\n",
    "        \n",
    "    elif method == \"triangle\":\n",
    "        Th = cv.threshold(img, 0, 255, cv.THRESH_TRIANGLE)[0]\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Method specified unavailable\")\n",
    "    \n",
    "    lowTh = (1-sigma) * Th\n",
    "    highTh = (1+sigma) *Th\n",
    "    \n",
    "    return cv.Canny(img, lowTh, highTh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34e60c",
   "metadata": {},
   "source": [
    "## Contour detection\n",
    "Contour detection is a higher-level process that involves identifying the complete outline or shape of an object within an image. It goes beyond simple edge detection by connecting the detected edges to form closed contours that represent the boundaries of objects. Contour detection methods can involve edge detection as an initial step, followed by algorithms that connect the detected edges to form closed curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d18350",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = np.zeros((256, 256), dtype=np.uint8)\n",
    "\n",
    "cv.rectangle(rect, (25, 25), (231, 231), 255, -1)\n",
    "\n",
    "show_img(\"rect\", rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9644ce89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours, _ = cv.findContours(rect, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5df27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 25,  25]],\n",
       " \n",
       "        [[ 25, 231]],\n",
       " \n",
       "        [[231, 231]],\n",
       " \n",
       "        [[231,  25]]], dtype=int32),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79247c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image\n",
    "img_bgr = cv.imread(\"images/monitor.jfif\")\n",
    "img = cv.imread(\"images/monitor.jfif\", 0)\n",
    "\n",
    "# threshold\n",
    "th = cv.threshold(img, 200, 255, cv.THRESH_BINARY_INV)[1]\n",
    "\n",
    "show_img(\"threshold\", th)\n",
    "\n",
    "contours, _ = cv.findContours(th, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9cbd82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134c68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.drawContours(img_bgr, contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "show_img(\"contours\", img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae68f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContours(th, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img_bgr_copy = img_bgr.copy()\n",
    "cv.drawContours(img_bgr_copy, contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "show_img(\"contours\", img_bgr_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c62466",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContours(th, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours with maximum number of points\n",
    "length = [len(c) for c in contours]\n",
    "contour_largest = contours[np.argmax(length)]\n",
    "\n",
    "img_bgr_copy = img_bgr.copy()\n",
    "cv.drawContours(img_bgr_copy, [contour_largest], -1, (0, 255, 0), 1)\n",
    "\n",
    "show_img(\"contours\", img_bgr_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e77bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31788924",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = contour_largest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a334e",
   "metadata": {},
   "source": [
    "## Contour features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv.moments(cnt)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fe808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid (center of mass)\n",
    "cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "print(f\"the centroid of monitor: {(cx, cy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area and perimeter\n",
    "area = cv.contourArea(cnt)\n",
    "peri = cv.arcLength(cnt, True)\n",
    "\n",
    "print(f\"The area of monitor: {area}\")\n",
    "print(f\"The perimeter of monitor: {peri:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b82435",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/remote-controller.webp\")\n",
    "\n",
    "show_img(\"img\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize -> grayscale -> bilateral filter -> edge detection -> find contour -> contour features\n",
    "factor = 300 / img.shape[1]\n",
    "img = cv.resize(img, None, fx=factor, fy=factor)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur = cv.bilateralFilter(gray, 7, 19, 13)\n",
    "edge = auto_canny(blur, method=\"triangle\")\n",
    "\n",
    "show_img(\"edge\", edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contour\n",
    "contours, _ = cv.findContours(edge, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "# area\n",
    "contours = sorted(contours, key=cv.contourArea, reverse=True)[:5]\n",
    "screen = None\n",
    "img_copy = img.copy()\n",
    "\n",
    "for c in contours:\n",
    "    peri = cv.arcLength(c, True)\n",
    "    approx = cv.approxPolyDP(c, 0.1*peri, True)\n",
    "    \n",
    "    if len(approx)==4:\n",
    "        screen = c\n",
    "        break\n",
    "\n",
    "cv.drawContours(img_copy, [screen], -1, (0, 255, 0), 2)\n",
    "show_img(\"screen\", img_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d0f6e",
   "metadata": {},
   "source": [
    "Circularity:\n",
    "\n",
    "$$circularity = \\frac{4 \\times \\pi \\times Area}{Perimeter^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe416d",
   "metadata": {},
   "source": [
    "### Demo on red object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2845852",
   "metadata": {},
   "outputs": [],
   "source": [
    "redLow1 = (0, 90, 40)\n",
    "redHigh1 = (10, 255, 210)\n",
    "\n",
    "redLow2 = (170, 90, 40)\n",
    "redHigh2 = (179, 255, 210)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    sys.exit(\"No webcam detected\")\n",
    "    \n",
    "# factor\n",
    "fixed_width = min_area = 500\n",
    "factor = fixed_width / cap.get(3)  # frame width\n",
    "kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "\n",
    "while (1):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"No frame received\")\n",
    "        break\n",
    "    \n",
    "    # resize, blur, change to hsv, inRange, mask integration, morphological operation, find contour, bounding box\n",
    "    resize = cv.resize(frame, None, fx=factor, fy=factor)\n",
    "    blur = cv.GaussianBlur(resized, (5, 5), 0)\n",
    "    img_hsv = cv.cvtColor(blur, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask1 = cv.inRange(img_hsv, redLow1, redHigh1)\n",
    "    mask2 = cv.inRange(img_hsv, redLow2, redHigh2)\n",
    "    mask = cv.add(mask1, mask2)\n",
    "    # suppress noise\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    # find contours\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    bbs = []\n",
    "    centroids = []\n",
    "    for c in contours:\n",
    "        area = cv.contourArea(c)\n",
    "        if area > min_area:\n",
    "            bb = cv.boundingRect(c)\n",
    "            M = cv.moments(c)\n",
    "            cx, cy = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
    "            centroids.append((cx, cy))\n",
    "            bbs.append(bb)\n",
    "            \n",
    "    for bb, centroid in zip(bbs, centroids):\n",
    "        x, y, w, h = bb\n",
    "        cv.rectangle(resized, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv.circle(resized, centroid, 2, (255, 0, 0), -1)\n",
    "        \n",
    "    cv.imshow(\"red object\", resized)\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18ee03",
   "metadata": {},
   "source": [
    "## Weekly Activity\n",
    "1. Experiment with different edge detectors: Sobel, Laplacian, Prewitt, Scharr derivatives and Canny operators (all with aperture size of 3) on image named 'pineapple.jfif'. Comment on the results.\n",
    "2. Write a program to identify the white object (probably laptop) present in the image 'electronic.jfif'. Draw bounding boxes on the objects.\n",
    "3. Isolate the clock with the aid of edge detection and contours' properties. The example result should be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "\n",
    "# Read the image in grayscale\n",
    "img = cv.imread(\"images/pineapple.jfif\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply a binary inverse threshold\n",
    "th = cv.threshold(img, 200, 255, cv.THRESH_BINARY_INV)[1]\n",
    "\n",
    "# Sobel edge detection\n",
    "sobelx_32f = cv.Sobel(th, cv.CV_32F, 1, 0, ksize=3)\n",
    "sobely_32f = cv.Sobel(th, cv.CV_32F, 0, 1, ksize=3)\n",
    "sobel = cv.magnitude(sobelx_32f, sobely_32f)\n",
    "\n",
    "# Laplacian edge detection\n",
    "laplacian = cv.Laplacian(img, cv.CV_32F, ksize=3)\n",
    "\n",
    "# Prewitt edge detection\n",
    "prewittx_kernel = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "prewitty_kernel = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "prewitt_x = cv.filter2D(img, cv.CV_32F, prewittx_kernel)\n",
    "prewitt_y = cv.filter2D(img, cv.CV_32F, prewitty_kernel)\n",
    "prewitt = cv.magnitude(prewitt_x, prewitt_y)\n",
    "\n",
    "# Scharr edge detection\n",
    "scharrx = cv.Scharr(img, cv.CV_32F, 1, 0)\n",
    "scharry = cv.Scharr(img, cv.CV_32F, 0, 1)\n",
    "scharr = cv.magnitude(scharrx, scharry)\n",
    "\n",
    "# Canny edge detection\n",
    "canny = cv.Canny(img, 30, 100)\n",
    "\n",
    "# Display the results\n",
    "cv.imshow(\"Original Image\", img)\n",
    "cv.imshow(\"Sobel\", sobel)\n",
    "cv.imshow(\"Laplacian\", laplacian)\n",
    "cv.imshow(\"Prewitt\", prewitt)\n",
    "cv.imshow(\"Scharr\", scharr)\n",
    "cv.imshow(\"Canny\", canny)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobel edge detection: \n",
    "# regions with abrupt intensity changes, such as the edges of objects, will be visible as bright lines against a darker background.\n",
    "\n",
    "# Laplacian edge detection：\n",
    "# edges and regions with significant intensity changes will be enhanced\n",
    "\n",
    "# Prewitt edge detection：\n",
    "# The edge of grass and pineapple cannot be seen.\n",
    "\n",
    "# Scharr edge detection：\n",
    "# The edge of grass and pineapple cannot be seen.\n",
    "\n",
    "# Canny edge detection：\n",
    "# Both edges of grass and pineapple cannot be detected and highligted clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43330847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "\n",
    "img = cv.imread(\"images/electronic.jfif\")\n",
    "\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "white_low = np.array([0, 0, 200])\n",
    "white_high = np.array([179, 50, 255])\n",
    "\n",
    "mask = cv.inRange(hsv, white_low, white_high)\n",
    "contours, _ = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img_copy = img.copy()\n",
    "\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv.boundingRect(contour)\n",
    "    cv.rectangle(img_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "show_img(\"White Objects\", img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60623ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "img = cv.imread(\"images/electronic.jfif\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to segment white regions\n",
    "th = cv.threshold(gray, 210, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "# Find contours in the thresholded image\n",
    "contours, _ = cv.findContours(th, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw bounding boxes\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv.boundingRect(contour)\n",
    "    cv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw bounding box\n",
    "\n",
    "cv.imshow(\"Bounding Box\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a029a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "img = cv.imread(\"images/clock.jpg\")\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "#perform edge detection on a blurred image\n",
    "edges = auto_canny(blur, method=\"triangle\")\n",
    "\n",
    "#find contours\n",
    "contours, _ = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "clock_contours = []\n",
    "\n",
    "min_circularity = 0.5\n",
    "max_circularity = 1.5\n",
    "\n",
    "# find potential circular objects (clocks)\n",
    "for contour in contours:\n",
    "    area = cv.contourArea(contour)\n",
    "    peri = cv.arcLength(contour, True)\n",
    "    circularity = (4 * np.pi * area) / (peri ** 2)\n",
    "#filter out contours that have circularity values outside this range\n",
    "    if min_circularity < circularity < max_circularity:\n",
    "        clock_contours.append(contour)\n",
    "    \n",
    "#each contour in the clock_contours list, which contains the filtered contours of circular objects\n",
    "#draw circular bounding box\n",
    "for contour in clock_contours:\n",
    "    # cv.minEnclosingCircle function calculates the minimum enclosing circle for the current contour.\n",
    "    (x, y), radius = cv.minEnclosingCircle(contour)\n",
    "    cv.circle(img, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "\n",
    "show_img(\"Isolated Clock\", img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
