{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274dea11",
   "metadata": {},
   "source": [
    "# Learning Outcomes\n",
    "1) Gentle into on CV (a subfield of AI)\n",
    "2) Recap image as Numpy array\n",
    "3) Splitting/merging channels\n",
    "4) Cropping\n",
    "5) Mathematical operations\n",
    "6) image blending (add 2 images tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae383fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >=(3,7)\n",
    "\n",
    "import cv2 as cv \n",
    "import numpy as np\n",
    "from util_func import show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff62446",
   "metadata": {},
   "source": [
    "# Recap on images as Numpy array\n",
    "There are 2  primary types of images: **grayscale** and **color**.\n",
    "\n",
    "Grayscale:\n",
    "matrix(2D array)\n",
    "(h,w)\n",
    "\n",
    "Color:\n",
    "3D array\n",
    "(h,w,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grayscale image\n",
    "img=np.zeros((2,4),dtype=np.uint8) # {[0,0,0,0][0,0,0,0]}\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color=cv.cvtColor(img,cv.COLOR_GRAY2BGR) #(h,w,channel)->(2,4,3) #from img above \n",
    "print(img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956dc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0,1]=50\n",
    "img[1,2]=150\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ed571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grayscale->color, stay grayscale,not color\n",
    "img_color=cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "print(img_color) #black/white/gray(150,150,150/50,50,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f54c61",
   "metadata": {},
   "source": [
    "# Access elements in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf862fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "a=img[49,219,2] ##take even is slightly slower\n",
    "b=img.item(49,219,2)\n",
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09277b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit a =img[49,219,2]\n",
    "%timeit b =img.item(49,219,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b1866c",
   "metadata": {},
   "source": [
    "# Numpy slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left slice\n",
    "\n",
    "h,w=img.shape[:2] #get h,w\n",
    "yc,xc=h//2,w//2 #get centre\n",
    "\n",
    "#slicing\n",
    "topleft=img[:yc,:xc] #0 until h//2\n",
    "\n",
    "show_img(\"topleft\",topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60x60 squared central region of the image\n",
    "\n",
    "centre=img[yc-30:yc+30, xc-30:xc+30]\n",
    "\n",
    "show_img(\"centre\",centre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3066c",
   "metadata": {},
   "source": [
    "# Create a white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2\n",
    "\n",
    "img=np.zeros((200,200))+255 #all 1 array (no need *255 ye ok)\n",
    "img=np.uint8(img)\n",
    "\n",
    "show_img(\"white\",img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfca736",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract region of interest\n",
    "\n",
    "img=cv.imread(\"images/flower.jfif\")\n",
    "\n",
    "show_img(\"img\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8415aa3",
   "metadata": {},
   "source": [
    "# There are 3 ways to get the indices needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df164f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(cv) if i.startswith(\"EVENT\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18995f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st way (to get the 4 parameters) (x1,y1,x2,y2)\n",
    "#tick 4 points to get the parameters in array, later can call\n",
    "img=cv.imread(\"images/flower.jfif\")\n",
    "img_copy=img.copy()\n",
    "\n",
    "\n",
    "def rect_region(event,x,y,flags,params):\n",
    "    if event==cv.EVENT_LBUTTONDOWN:\n",
    "        print((x,y))\n",
    "        cv.circle(img,(x,y),1,(0,0,255),-1)\n",
    "        cv.imshow(\"img\",img)\n",
    "        \n",
    "cv.imshow(\"img\",img)\n",
    "cv.setMouseCallback(\"img\",rect_region)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d75654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the some indices of the image wanted\n",
    "#take img_copy de yi ge xiao part after knowing the x1,y1,x2,y2\n",
    "\n",
    "flower=img_copy[41:120,89:173]\n",
    "\n",
    "show_img(\"flower\",flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f39fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd way (x,y,w,h)\n",
    "#drag the area of interest\n",
    "bbox=cv.selectROI(\"crop\",img_copy) #can select which part wan to crop,drag the area\n",
    "\n",
    "\n",
    "flower=img_copy[int(bbox[1]):int(bbox[1]+bbox[3]),\n",
    "                int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "\n",
    "show_img(\"flower\",flower)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a84cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd way: paint app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr=np.zeros((30,30),dtype=np.uint8)\n",
    "\n",
    "#assign the white region\n",
    "img_arr[:10,10:20]=255\n",
    "img_arr[10:20,:10]=255\n",
    "img_arr[10:20,20:]=255\n",
    "img_arr[20:,10:20]=255\n",
    "\n",
    "img=np.tile(img_arr,(3,3)) #3,3 for repeating for horizontal and vertical respectively\n",
    "\n",
    "show_img(\"pattern\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714a3aa",
   "metadata": {},
   "source": [
    "# image cropping\n",
    "why?\n",
    "1) Remove unwanted object\n",
    "2) Separate the image into a $3 \\times 3$grids. We move/adjust the camera in such a way that the object of interest lies on the gridlines or their intersections. As such, your image would look more aethetically appealing. This is known as rule of thirds.\n",
    "3) One of the image augmentation methods for DL model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a4136",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(\"images/dog.jfif\")\n",
    "img_copy=img.copy()\n",
    "\n",
    "h,w=img.shape[:2]\n",
    "#User defined parameters\n",
    "n_vertical_grids=4\n",
    "n_horizontal_grids=4\n",
    "\n",
    "#1st rectangle\n",
    "M=int(h/n_vertical_grids)\n",
    "N=int(w/n_horizontal_grids)\n",
    "\n",
    "tiles=[]\n",
    "\n",
    "#draw the h,w rectangle\n",
    "for y in range(0,h,M):\n",
    "    for x in range(0,w,N):\n",
    "        #adjust\n",
    "        x1=x+N\n",
    "        y1=y+M\n",
    "        \n",
    "        if x1>w and y1>h:\n",
    "            x1=w-1 #拉回来\n",
    "            y1=h-1\n",
    "            cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "            tile=img[y:h,x:w] #put in array later can easily call the indices wanted\n",
    "            tiles.append(tile)\n",
    "            \n",
    "        elif y1>h:\n",
    "            y1=h-1\n",
    "            cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "            tile=img[y:h,x:x1]\n",
    "            tiles.append(tile)\n",
    "        \n",
    "        elif x1>w:\n",
    "            x1=w-1\n",
    "            cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "            tile=img[y:y1,x:w]\n",
    "            tiles.append(tile)\n",
    "            \n",
    "        else:\n",
    "            cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "            tile=img[y:y1,x:x1]\n",
    "            tiles.append(tile)\n",
    "\n",
    "show_img(\"crop\",img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3676e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(\"patch\",tiles[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733fe7a",
   "metadata": {},
   "source": [
    "# Splitting and merging colour channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "(b,g,r)=cv.split(img) #below can use b,g,r\n",
    "img_merge=cv.merge((b,g,r))\n",
    "\n",
    "#show img,img_merge (split then merge) are same\n",
    "np.array_equal(img,img_merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the figure into b,g,r\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(12,4),sharey=True)\n",
    "fig.suptitle(\"Different color channels\")\n",
    "\n",
    "ax1.imshow(b,cmap=plt.cm.gray)\n",
    "ax1.set(title=\"blue channel\",xticks=[],yticks=[])\n",
    "ax2.imshow(g,cmap=plt.cm.gray)\n",
    "ax2.set(title=\"green channel\",xticks=[],yticks=[])\n",
    "ax3.imshow(r,cmap=plt.cm.gray)\n",
    "ax3.set(title=\"red channel\",xticks=[],yticks=[])\n",
    "\n",
    "plt.tight_layout() #show in 3 figure in row\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2caf3",
   "metadata": {},
   "source": [
    "# display different channels in color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make G,R to be 0 and B=255 to look B more brighter\n",
    "\n",
    "img=cv.imread(\"images/dog.jfif\")\n",
    "\n",
    "channels=cv.split(img)\n",
    "\n",
    "#this color varible will be window names\n",
    "colors=(\"blue\",\"green\",\"red\")\n",
    "\n",
    "imgs=[] #grab b,g,r into this imgs\n",
    "\n",
    "for i,ch in enumerate(channels):\n",
    "    img_arr=np.zeros_like(img)\n",
    "    img_arr[...,i]=ch\n",
    "    imgs.append(img_arr)\n",
    "    \n",
    "for c,img in zip(colors,imgs):\n",
    "    cv.imshow(c,img)\n",
    "    \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb5280",
   "metadata": {},
   "source": [
    "# Point operators\n",
    "\n",
    "Elementary math operations:addition, substraction, multiplication, and division\n",
    "\n",
    "1) alpha = x or //\n",
    "2) beta = + or -\n",
    "when alpha>1, contrast will increase.\n",
    "\n",
    "when 0<alpha<1, contrast will decrease.\n",
    "\n",
    "when beta>0, brightness will increase.\n",
    "\n",
    "when beta<0, brightness will decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.uint8(np.array([-2,0,259,300])) #-2 is 254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fad3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha > 1 (high contrast)\n",
    "# 0 < alpha < 1 (low contrast)\n",
    "# beta > 0 (brightness high)\n",
    "# beta < 0 (brightness low)\n",
    "\n",
    "def point_op(img,alpha,beta):\n",
    "    \"\"\"point operators of image.Arguments:\n",
    "    1. source image\n",
    "    2. multiplier\n",
    "    3. constant\"\"\"\n",
    "    img=img.astype(float)\n",
    "    res=alpha*img+beta #the formula\n",
    "    res=np.clip(res,0,255) #lower and upper limit\n",
    "    return np.uint8(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcaebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(\"images/bridge.jfif\")\n",
    "\n",
    "#increase the brightness and contrast\n",
    "transform=point_op(img,1.6,20)\n",
    "\n",
    "cv.imshow(\"original\",img)\n",
    "show_img(\"transform\",transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea375218",
   "metadata": {},
   "outputs": [],
   "source": [
    "darken=point_op(img,1,-80)\n",
    "show_img(\"img\",darken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab235b",
   "metadata": {},
   "source": [
    "# Gamma Correction\n",
    "\n",
    "Technique to adjust the brightness of image.\n",
    "\n",
    "#dark area become brighter\n",
    "\n",
    "gamma<1, make dark area brighter\n",
    "\n",
    "gamma>1, make dark area darker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d999b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma can be high or low to adjust the brightness of the image\n",
    "gamma=1/2.2 \n",
    "\n",
    "lookUpTable=np.empty((1,256),dtype=np.uint8) #lookuptable:1-155\n",
    "\n",
    "for i in range(256):\n",
    "    lookUpTable[0,i]=np.clip(pow(i/255.0,gamma)*255.0,0,255) #clip: to put the formula inside # the formula \n",
    "\n",
    "img=cv.imread(\"images/mountains_prop.jpg\")\n",
    "res=cv.LUT(img,lookUpTable)\n",
    "\n",
    "cv.namedWindow(\"original\",cv.WINDOW_NORMAL)\n",
    "cv.imshow(\"original\",img)\n",
    "show_img(\"gamma correction\",res,adjust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d562544",
   "metadata": {},
   "source": [
    "# Image blending (add 2 images)\n",
    "```\n",
    "cv.addWeighted(img1,alpha,img2,1-alpha,beta)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da46e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge 2 images\n",
    "\n",
    "img=cv.imread(\"images/lena.jfif\")\n",
    "img2=cv.imread(\"images/coins.jfif\")\n",
    "\n",
    "#resize img2 to be same dimension as img\n",
    "h,w=img.shape[:2]\n",
    "img2=cv.resize(img2,(w,h)) #w 1st\n",
    "alpha=0.7\n",
    "\n",
    "res=cv.addWeighted(img,alpha,img2, 1-alpha,0) #alpha:0.7 (img 70% visible), 1-alpha=0.3 (img2 30% visible)\n",
    "\n",
    "cv.imshow(\"lena\",img)\n",
    "cv.imshow(\"resized coin\",img2)\n",
    "show_img(\"image blending\",res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c602c",
   "metadata": {},
   "source": [
    "# Exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a001a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "width = 450\n",
    "height = 350\n",
    "\n",
    "random_noise_color_image = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8) #3 color channels (Red, Green, and Blue)\n",
    "\n",
    "random_grayscale_image = np.random.randint(0, 256, (height, width), dtype=np.uint8)\n",
    "\n",
    "cv.imshow(\"Noise Color\", random_noise_color_image)\n",
    "cv.imshow(\"Noise Grayscale\", random_grayscale_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a737a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "def crop_grid (img, num_horizontal_grid, num_vertical_grid, line_color):\n",
    "    img=cv.imread(img)\n",
    "    img_copy=img.copy()\n",
    "\n",
    "    h,w=img.shape[:2]\n",
    "    #User defined parameters\n",
    "    n_vertical_grids=num_vertical_grid\n",
    "    n_horizontal_grids=num_horizontal_grid\n",
    "\n",
    "    #1st rectangle\n",
    "    M=int(h/n_vertical_grids)\n",
    "    N=int(w/n_horizontal_grids)\n",
    "\n",
    "    tiles=[]\n",
    "\n",
    "    #draw the h,w rectangle\n",
    "    for y in range(0,h,M):\n",
    "        for x in range(0,w,N):\n",
    "            #adjust\n",
    "            x1=x+N\n",
    "            y1=y+M\n",
    "        \n",
    "            if x1>w and y1>h:\n",
    "                x1=w-1 #pull back\n",
    "                y1=h-1\n",
    "                cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "                tile=img[y:h,x:w] #put in array later can easily call the indices wanted\n",
    "                tiles.append(tile)\n",
    "            \n",
    "            elif y1>h:\n",
    "                y1=h-1\n",
    "                cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "                tile=img[y:h,x:x1]\n",
    "                tiles.append(tile)\n",
    "        \n",
    "            elif x1>w:\n",
    "                x1=w-1\n",
    "                cv.rectangle(img_copy,(x,y),(x1,y1),(0,255,0),1) #start,end,color,brightness\n",
    "                tile=img[y:y1,x:w]\n",
    "                tiles.append(tile)\n",
    "            \n",
    "            else:\n",
    "                cv.rectangle(img_copy,(x,y),(x1,y1),line_color,1) #start,end,color,brightness\n",
    "                tile=img[y:y1,x:x1]\n",
    "                tiles.append(tile)\n",
    "\n",
    "    show_img(\"crop_grid\",img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9613ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_grid(\"images/dog.jfif\",5,5,(0,255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f432b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "img2 = cv.imread(\"images/coins.jfif\")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "img2 = cv.resize(img2, (w, h))\n",
    "\n",
    "\n",
    "# Perform image blending with smooth transition and display the sequence\n",
    "for alpha in range(60):\n",
    "    # Calculate the alpha value for blending (ranges from 0 to 1)\n",
    "    alpha = alpha / 60\n",
    "\n",
    "    res = cv.addWeighted(img, alpha, img2, 1 - alpha, 0)\n",
    "\n",
    "    # Display the blended image with a delay for smoother transition\n",
    "    cv.imshow(\"Image Blending\", res)\n",
    "    cv.waitKey(20)  # Adjust the delay (in milliseconds) between each frame\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9841e",
   "metadata": {},
   "source": [
    "# Adding watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "watermark=cv.imread(\"Picture1.png\")\n",
    "\n",
    "show_img(\"watermark\",watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad677e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(\"images/travel_hd.jpg\")\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a965c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay have same dimension with img but in 0\n",
    "overlay=np.zeros_like(img)\n",
    "\n",
    "#get height and width\n",
    "h,w=img.shape[:2]\n",
    "hW,wW=watermark.shape[:2]\n",
    "\n",
    "overlay[h-hW-15:h-15,15:15+wW]=watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add watermark into the img\n",
    "watermarked_img=cv.addWeighted(img,1,overlay,0.4,0)\n",
    "\n",
    "show_img(\"watermark\",watermarked_img,adjust=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
